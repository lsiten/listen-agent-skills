#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é—®å·è°ƒæŸ¥æŠ¥å‘Šæ•°æ®åˆ†æè„šæœ¬
æ”¯æŒå¤šç§æ•°æ®æ ¼å¼å’Œæ—§æ–¹æ¡ˆæ ¼å¼ï¼Œè‡ªåŠ¨é€‰æ‹©åˆ†ææ¨¡å‹ï¼Œç”ŸæˆHTMLæŠ¥å‘Š
"""

import argparse
import sys
import os
import json
import re
from pathlib import Path
from datetime import datetime
import webbrowser

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from jinja2 import Template

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®seabornæ ·å¼
sns.set_style("whitegrid")
sns.set_palette("husl")


def load_data_file(file_path):
    """åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    file_path = Path(file_path)
    if not file_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    ext = file_path.suffix.lower()
    
    try:
        if ext == '.csv':
            df = pd.read_csv(file_path, encoding='utf-8')
        elif ext in ['.xlsx', '.xls']:
            df = pd.read_excel(file_path)
        elif ext == '.json':
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            df = pd.DataFrame(data)
        elif ext == '.txt':
            # å°è¯•å¤šç§åˆ†éš”ç¬¦
            for sep in [',', '\t', '|', ';']:
                try:
                    df = pd.read_csv(file_path, sep=sep, encoding='utf-8')
                    if len(df.columns) > 1:
                        break
                except:
                    continue
            else:
                raise ValueError("æ— æ³•è§£æTXTæ–‡ä»¶ï¼Œè¯·ç¡®ä¿ä½¿ç”¨æ ‡å‡†åˆ†éš”ç¬¦ï¼ˆé€—å·ã€åˆ¶è¡¨ç¬¦ç­‰ï¼‰")
        elif ext == '.md':
            # è¯»å–Markdownæ–‡ä»¶ï¼Œæå–è¡¨æ ¼
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            # æŸ¥æ‰¾Markdownè¡¨æ ¼
            tables = re.findall(r'\|.*\|', content, re.MULTILINE)
            if tables:
                # è§£æç¬¬ä¸€ä¸ªè¡¨æ ¼
                lines = [line.strip() for line in tables[0].split('\n') if '|' in line]
                if len(lines) >= 2:
                    headers = [h.strip() for h in lines[0].split('|')[1:-1]]
                    data_rows = []
                    for line in lines[2:]:  # è·³è¿‡åˆ†éš”è¡Œ
                        row = [cell.strip() for cell in line.split('|')[1:-1]]
                        if row:
                            data_rows.append(row)
                    df = pd.DataFrame(data_rows, columns=headers)
                else:
                    raise ValueError("Markdownæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¡¨æ ¼")
            else:
                raise ValueError("Markdownæ–‡ä»¶ä¸­æœªæ‰¾åˆ°è¡¨æ ¼")
        elif ext == '.docx':
            try:
                from docx import Document
                doc = Document(file_path)
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªè¡¨æ ¼
                if doc.tables:
                    table = doc.tables[0]
                    headers = [cell.text.strip() for cell in table.rows[0].cells]
                    data_rows = []
                    for row in table.rows[1:]:
                        data_rows.append([cell.text.strip() for cell in row.cells])
                    df = pd.DataFrame(data_rows, columns=headers)
                else:
                    raise ValueError("Wordæ–‡ä»¶ä¸­æœªæ‰¾åˆ°è¡¨æ ¼")
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£…python-docxåº“: pip install python-docx")
        elif ext == '.pdf':
            try:
                import pdfplumber
                # å°è¯•ä»PDFä¸­æå–è¡¨æ ¼
                with pdfplumber.open(file_path) as pdf:
                    tables = []
                    for page in pdf.pages:
                        page_tables = page.extract_tables()
                        if page_tables:
                            tables.extend(page_tables)
                    
                    if tables:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¡¨æ ¼
                        table_data = tables[0]
                        if len(table_data) >= 2:
                            headers = [str(cell).strip() if cell else f'Column_{i}' 
                                      for i, cell in enumerate(table_data[0])]
                            data_rows = []
                            for row in table_data[1:]:
                                if row and any(cell for cell in row):
                                    # ç¡®ä¿åˆ—æ•°ä¸€è‡´
                                    row_data = [str(cell).strip() if cell else '' 
                                               for cell in row]
                                    # è¡¥é½ç¼ºå¤±çš„åˆ—
                                    while len(row_data) < len(headers):
                                        row_data.append('')
                                    # æˆªæ–­å¤šä½™çš„åˆ—
                                    row_data = row_data[:len(headers)]
                                    data_rows.append(row_data)
                            if data_rows:
                                df = pd.DataFrame(data_rows, columns=headers)
                            else:
                                raise ValueError("PDFè¡¨æ ¼ä¸­æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
                        else:
                            raise ValueError("PDFè¡¨æ ¼æ ¼å¼ä¸æ­£ç¡®")
                    else:
                        # å¦‚æœæ²¡æœ‰è¡¨æ ¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–è¡¨æ ¼æ•°æ®
                        print("   PDFä¸­æœªæ‰¾åˆ°è¡¨æ ¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–æ•°æ®...")
                        all_text = []
                        for page in pdf.pages:
                            text = page.extract_text()
                            if text:
                                all_text.append(text)
                        
                        # å°è¯•ä»æ–‡æœ¬ä¸­è§£æè¡¨æ ¼
                        text_content = '\n'.join(all_text)
                        lines = [line.strip() for line in text_content.split('\n') if line.strip()]
                        
                        # æŸ¥æ‰¾å¯èƒ½åŒ…å«è¡¨æ ¼çš„è¡Œ
                        table_lines = []
                        for line in lines:
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªåˆ†éš”ç¬¦ï¼ˆå¯èƒ½æ˜¯è¡¨æ ¼è¡Œï¼‰
                            if sum(line.count(sep) for sep in [',', '\t', '|', ';']) >= 2:
                                table_lines.append(line)
                        
                        if table_lines and len(table_lines) >= 2:
                            # å°è¯•è§£æä¸ºè¡¨æ ¼
                            for sep in [',', '\t', '|', ';']:
                                try:
                                    data_rows = []
                                    for line in table_lines:
                                        parts = [p.strip() for p in line.split(sep) if p.strip()]
                                        if len(parts) > 1:
                                            data_rows.append(parts)
                                    
                                    if len(data_rows) >= 2:
                                        # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
                                        headers = data_rows[0]
                                        df = pd.DataFrame(data_rows[1:], columns=headers)
                                        break
                                except:
                                    continue
                            else:
                                raise ValueError("PDFæ–‡ä»¶ä¸­æœªæ‰¾åˆ°å¯è§£æçš„è¡¨æ ¼æ•°æ®")
                        else:
                            raise ValueError("PDFæ–‡ä»¶ä¸­æœªæ‰¾åˆ°è¡¨æ ¼ï¼Œè¯·ç¡®ä¿PDFåŒ…å«è¡¨æ ¼æ•°æ®")
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£…pdfplumberåº“: pip install pdfplumber")
        elif ext in ['.png', '.jpg', '.jpeg']:
            try:
                import pytesseract
                from PIL import Image
                import io
                
                # ä½¿ç”¨OCRè¯†åˆ«å›¾ç‰‡ä¸­çš„è¡¨æ ¼
                print("   æ­£åœ¨ä½¿ç”¨OCRè¯†åˆ«å›¾ç‰‡ä¸­çš„è¡¨æ ¼æ•°æ®...")
                image = Image.open(file_path)
                
                # å°è¯•ä½¿ç”¨OCRæå–æ–‡æœ¬
                ocr_text = pytesseract.image_to_string(image, lang='chi_sim+eng')
                
                # å°è¯•è§£æè¡¨æ ¼æ ¼å¼çš„æ–‡æœ¬
                lines = [line.strip() for line in ocr_text.split('\n') if line.strip()]
                
                # æŸ¥æ‰¾åŒ…å«åˆ†éš”ç¬¦çš„è¡Œï¼ˆå¯èƒ½æ˜¯è¡¨æ ¼ï¼‰
                table_lines = []
                for line in lines:
                    if any(sep in line for sep in [',', '\t', '|', ';', '  ']):
                        table_lines.append(line)
                
                if table_lines:
                    # å°è¯•è§£æä¸ºè¡¨æ ¼
                    for sep in [',', '\t', '|', ';']:
                        try:
                            data_rows = []
                            for line in table_lines:
                                parts = [p.strip() for p in line.split(sep) if p.strip()]
                                if len(parts) > 1:
                                    data_rows.append(parts)
                            
                            if len(data_rows) >= 2:
                                # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
                                headers = data_rows[0]
                                df = pd.DataFrame(data_rows[1:], columns=headers)
                                break
                        except:
                            continue
                    else:
                        raise ValueError("æ— æ³•ä»å›¾ç‰‡ä¸­è¯†åˆ«å‡ºè¡¨æ ¼æ ¼å¼ï¼Œè¯·ç¡®ä¿å›¾ç‰‡æ¸…æ™°ä¸”åŒ…å«è¡¨æ ¼æ•°æ®")
                else:
                    raise ValueError("å›¾ç‰‡ä¸­æœªè¯†åˆ«å‡ºè¡¨æ ¼æ•°æ®ï¼Œè¯·ç¡®ä¿å›¾ç‰‡æ¸…æ™°ä¸”åŒ…å«è¡¨æ ¼")
                    
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£…pytesseractå’ŒPillowåº“: pip install pytesseract Pillow\n"
                               "è¿˜éœ€è¦å®‰è£…Tesseract OCRå¼•æ“: brew install tesseract (macOS)")
            except Exception as e:
                error_msg = str(e).lower()
                if "tesseract" in error_msg or "tesseract not found" in error_msg:
                    raise ImportError("Tesseract OCRæœªå®‰è£…æˆ–æœªé…ç½®ã€‚\n"
                                    "å®‰è£…æ–¹æ³•:\n"
                                    "  macOS: brew install tesseract\n"
                                    "  Ubuntu/Debian: sudo apt-get install tesseract-ocr\n"
                                    "  Windows: ä¸‹è½½å®‰è£… https://github.com/UB-Mannheim/tesseract/wiki")
                raise
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
        
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®æ–‡ä»¶: {file_path}")
        print(f"   æ•°æ®å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
        return df
    
    except Exception as e:
        raise ValueError(f"åŠ è½½æ–‡ä»¶å¤±è´¥: {str(e)}")


def load_old_plan(file_path):
    """åŠ è½½æ—§æ–¹æ¡ˆæ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    file_path = Path(file_path)
    if not file_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    ext = file_path.suffix.lower()
    
    try:
        if ext == '.md':
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return content
        elif ext == '.docx':
            try:
                from docx import Document
                doc = Document(file_path)
                content = '\n'.join([para.text for para in doc.paragraphs])
                return content
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£…python-docxåº“: pip install python-docx")
        elif ext == '.pptx':
            try:
                from pptx import Presentation
                prs = Presentation(file_path)
                content_parts = []
                for slide in prs.slides:
                    for shape in slide.shapes:
                        if hasattr(shape, "text"):
                            content_parts.append(shape.text)
                return '\n'.join(content_parts)
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£…python-pptxåº“: pip install python-pptx")
        elif ext == '.pdf':
            try:
                import pdfplumber
                content_parts = []
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages:
                        text = page.extract_text()
                        if text:
                            content_parts.append(text)
                return '\n\n'.join(content_parts)
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£…pdfplumberåº“: pip install pdfplumber")
        elif ext in ['.png', '.jpg', '.jpeg']:
            try:
                import pytesseract
                from PIL import Image
                
                print("   æ­£åœ¨ä½¿ç”¨OCRè¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡æœ¬å†…å®¹...")
                image = Image.open(file_path)
                content = pytesseract.image_to_string(image, lang='chi_sim+eng')
                return content
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£…pytesseractå’ŒPillowåº“: pip install pytesseract Pillow\n"
                               "è¿˜éœ€è¦å®‰è£…Tesseract OCRå¼•æ“: brew install tesseract (macOS)")
            except Exception as e:
                error_msg = str(e).lower()
                if "tesseract" in error_msg or "tesseract not found" in error_msg:
                    raise ImportError("Tesseract OCRæœªå®‰è£…æˆ–æœªé…ç½®ã€‚\n"
                                    "å®‰è£…æ–¹æ³•:\n"
                                    "  macOS: brew install tesseract\n"
                                    "  Ubuntu/Debian: sudo apt-get install tesseract-ocr\n"
                                    "  Windows: ä¸‹è½½å®‰è£… https://github.com/UB-Mannheim/tesseract/wiki")
                raise
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ—§æ–¹æ¡ˆæ ¼å¼: {ext}")
    
    except Exception as e:
        raise ValueError(f"åŠ è½½æ—§æ–¹æ¡ˆæ–‡ä»¶å¤±è´¥: {str(e)}")


def select_analysis_model(df):
    """æ ¹æ®æ•°æ®ç‰¹å¾è‡ªåŠ¨é€‰æ‹©åˆ†ææ¨¡å‹"""
    n_samples = len(df)
    n_vars = len(df.columns)
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    n_numeric = len(numeric_cols)
    
    print(f"\nğŸ“Š æ•°æ®ç‰¹å¾åˆ†æ:")
    print(f"   æ ·æœ¬æ•°: {n_samples}")
    print(f"   å˜é‡æ•°: {n_vars}")
    print(f"   æ•°å€¼å˜é‡: {n_numeric}")
    
    models = []
    
    # 1. æè¿°æ€§ç»Ÿè®¡ï¼ˆæ€»æ˜¯æ‰§è¡Œï¼‰
    models.append('descriptive')
    
    # 2. ç›¸å…³æ€§åˆ†æï¼ˆå¦‚æœæœ‰ä¸¤ä¸ªä»¥ä¸Šæ•°å€¼å˜é‡ï¼‰
    if n_numeric >= 2:
        models.append('correlation')
    
    # 3. å›å½’åˆ†æï¼ˆå¦‚æœæœ‰å› å˜é‡å’Œè‡ªå˜é‡ï¼‰
    if n_numeric >= 2 and n_samples >= 30:
        models.append('regression')
    
    # 4. èšç±»åˆ†æï¼ˆæ ·æœ¬é‡è¶³å¤Ÿï¼‰
    if n_samples >= 50 and n_numeric >= 2:
        models.append('cluster')
    
    # 5. å› å­åˆ†æï¼ˆå˜é‡æ•°é‡å¤šï¼‰
    if n_numeric >= 5 and n_samples >= 100:
        models.append('factor')
    
    print(f"   æ¨èæ¨¡å‹: {', '.join(models)}")
    return models


def perform_descriptive_analysis(df):
    """æè¿°æ€§ç»Ÿè®¡åˆ†æ"""
    results = {
        'summary': df.describe().to_dict(),
        'missing': df.isnull().sum().to_dict(),
        'dtypes': df.dtypes.astype(str).to_dict()
    }
    return results


def perform_correlation_analysis(df):
    """ç›¸å…³æ€§åˆ†æ"""
    numeric_df = df.select_dtypes(include=[np.number])
    if len(numeric_df.columns) < 2:
        return None
    
    corr_matrix = numeric_df.corr()
    return {
        'matrix': corr_matrix.to_dict(),
        'strong_pairs': []
    }


def perform_regression_analysis(df):
    """å›å½’åˆ†æ"""
    numeric_df = df.select_dtypes(include=[np.number])
    if len(numeric_df.columns) < 2:
        return None
    
    # é€‰æ‹©ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—ä½œä¸ºå› å˜é‡
    y_col = numeric_df.columns[0]
    X_cols = numeric_df.columns[1:].tolist()
    
    if not X_cols:
        return None
    
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import r2_score
    
    X = numeric_df[X_cols]
    y = numeric_df[y_col]
    
    # å¤„ç†ç¼ºå¤±å€¼
    mask = ~(X.isnull().any(axis=1) | y.isnull())
    X_clean = X[mask]
    y_clean = y[mask]
    
    if len(X_clean) < 10:
        return None
    
    model = LinearRegression()
    model.fit(X_clean, y_clean)
    y_pred = model.predict(X_clean)
    r2 = r2_score(y_clean, y_pred)
    
    return {
        'target': y_col,
        'features': X_cols,
        'r2_score': float(r2),
        'coefficients': {col: float(coef) for col, coef in zip(X_cols, model.coef_)},
        'intercept': float(model.intercept_)
    }


def perform_cluster_analysis(df):
    """èšç±»åˆ†æ"""
    numeric_df = df.select_dtypes(include=[np.number])
    if len(numeric_df.columns) < 2:
        return None
    
    # å¤„ç†ç¼ºå¤±å€¼
    numeric_df = numeric_df.dropna()
    if len(numeric_df) < 10:
        return None
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(numeric_df)
    
    # K-meansèšç±»
    n_clusters = min(5, len(numeric_df) // 10)
    if n_clusters < 2:
        return None
    
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X_scaled)
    
    return {
        'n_clusters': int(n_clusters),
        'cluster_labels': clusters.tolist(),
        'inertia': float(kmeans.inertia_)
    }


def perform_factor_analysis(df):
    """å› å­åˆ†æ"""
    numeric_df = df.select_dtypes(include=[np.number])
    if len(numeric_df.columns) < 3:
        return None
    
    numeric_df = numeric_df.dropna()
    if len(numeric_df) < 10:
        return None
    
    # PCAé™ç»´
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(numeric_df)
    
    pca = PCA(n_components=min(3, len(numeric_df.columns)))
    pca.fit(X_scaled)
    
    return {
        'n_components': int(pca.n_components_),
        'explained_variance_ratio': [float(v) for v in pca.explained_variance_ratio_],
        'total_variance_explained': float(sum(pca.explained_variance_ratio_))
    }


def generate_charts(df, output_dir, html_output_path):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    charts = {}
    numeric_df = df.select_dtypes(include=[np.number])
    
    # è®¡ç®—ç›¸å¯¹è·¯å¾„
    html_dir = Path(html_output_path).parent
    charts_dir = html_dir / 'charts'
    charts_dir.mkdir(exist_ok=True)
    
    # 1. æ•°å€¼å˜é‡åˆ†å¸ƒå›¾
    if len(numeric_df.columns) > 0:
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        axes = axes.flatten()
        
        for i, col in enumerate(numeric_df.columns[:4]):
            if i < len(axes):
                axes[i].hist(numeric_df[col].dropna(), bins=20, edgecolor='black')
                axes[i].set_title(f'{col} åˆ†å¸ƒ', fontsize=12)
                axes[i].set_xlabel(col)
                axes[i].set_ylabel('é¢‘æ•°')
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(numeric_df.columns), len(axes)):
            axes[i].axis('off')
        
        plt.tight_layout()
        dist_path = charts_dir / 'distribution_chart.png'
        plt.savefig(dist_path, dpi=150, bbox_inches='tight')
        plt.close()
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
        charts['distribution'] = f'charts/{dist_path.name}'
    
    # 2. ç›¸å…³æ€§çƒ­åŠ›å›¾
    if len(numeric_df.columns) >= 2:
        fig, ax = plt.subplots(figsize=(10, 8))
        corr = numeric_df.corr()
        sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,
                   square=True, linewidths=1, cbar_kws={"shrink": .8}, ax=ax)
        ax.set_title('å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=14, pad=20)
        plt.tight_layout()
        corr_path = charts_dir / 'correlation_heatmap.png'
        plt.savefig(corr_path, dpi=150, bbox_inches='tight')
        plt.close()
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
        charts['correlation'] = f'charts/{corr_path.name}'
    
    return charts


def evaluate_old_plan(old_plan_content, analysis_results):
    """è¯„ä¼°æ—§æ–¹æ¡ˆ"""
    evaluation = {
        'summary': '',
        'strengths': [],
        'weaknesses': [],
        'recommendations': []
    }
    
    # ç®€å•çš„è¯„ä¼°é€»è¾‘ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•ï¼‰
    plan_lower = old_plan_content.lower()
    
    # æ£€æŸ¥æ˜¯å¦æåˆ°æ•°æ®åˆ†æ
    if 'åˆ†æ' in plan_lower or 'analysis' in plan_lower:
        evaluation['strengths'].append('æ–¹æ¡ˆä¸­åŒ…å«äº†æ•°æ®åˆ†æç›¸å…³å†…å®¹')
    else:
        evaluation['weaknesses'].append('æ–¹æ¡ˆä¸­ç¼ºå°‘æ˜ç¡®çš„æ•°æ®åˆ†æè®¡åˆ’')
    
    # æ£€æŸ¥æ ·æœ¬é‡
    sample_size = analysis_results.get('data_info', {}).get('n_samples', 0)
    if sample_size < 30:
        evaluation['weaknesses'].append(f'æ ·æœ¬é‡è¾ƒå°ï¼ˆ{sample_size}ï¼‰ï¼Œå¯èƒ½å½±å“ç»Ÿè®¡æ˜¾è‘—æ€§')
        evaluation['recommendations'].append('å»ºè®®å¢åŠ æ ·æœ¬é‡è‡³è‡³å°‘30ä¸ªï¼Œä»¥æé«˜åˆ†æçš„å¯ä¿¡åº¦')
    elif sample_size >= 100:
        evaluation['strengths'].append(f'æ ·æœ¬é‡å……è¶³ï¼ˆ{sample_size}ï¼‰ï¼Œé€‚åˆè¿›è¡Œæ·±åº¦åˆ†æ')
    
    # æ£€æŸ¥å˜é‡æ•°é‡
    n_vars = analysis_results.get('data_info', {}).get('n_vars', 0)
    if n_vars < 3:
        evaluation['weaknesses'].append('å˜é‡æ•°é‡è¾ƒå°‘ï¼Œåˆ†æç»´åº¦æœ‰é™')
        evaluation['recommendations'].append('å»ºè®®å¢åŠ æ›´å¤šè°ƒç ”ç»´åº¦ï¼Œä¸°å¯Œæ•°æ®å†…å®¹')
    
    evaluation['summary'] = f"åŸºäºæ•°æ®åˆ†æç»“æœï¼Œå¯¹æ—§æ–¹æ¡ˆè¿›è¡Œäº†è¯„ä¼°ã€‚å‘ç°{len(evaluation['strengths'])}ä¸ªä¼˜ç‚¹å’Œ{len(evaluation['weaknesses'])}ä¸ªéœ€è¦æ”¹è¿›çš„åœ°æ–¹ã€‚"
    
    return evaluation


def generate_html_report(analysis_results, charts, old_plan_eval, title, output_path):
    """ç”ŸæˆHTMLæŠ¥å‘Š"""
    
    html_template = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ title }}</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
            padding: 20px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 30px;
        }
        h2 {
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            padding-left: 10px;
            border-left: 4px solid #3498db;
        }
        h3 {
            color: #555;
            margin-top: 25px;
            margin-bottom: 15px;
        }
        .meta-info {
            background: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 30px;
        }
        .meta-info p {
            margin: 5px 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #3498db;
            color: white;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .chart-container {
            text-align: center;
            margin: 30px 0;
        }
        .chart-container img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .strength {
            color: #27ae60;
            background: #d5f4e6;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .weakness {
            color: #e74c3c;
            background: #fadbd8;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .recommendation {
            color: #2980b9;
            background: #d6eaf8;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .section {
            margin: 30px 0;
        }
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>{{ title }}</h1>
        
        <div class="meta-info">
            <p><strong>ç”Ÿæˆæ—¶é—´:</strong> {{ generation_time }}</p>
            <p><strong>æ•°æ®æ ·æœ¬æ•°:</strong> {{ data_info.n_samples }}</p>
            <p><strong>å˜é‡æ•°é‡:</strong> {{ data_info.n_vars }}</p>
            <p><strong>ä½¿ç”¨çš„åˆ†ææ¨¡å‹:</strong> {{ ', '.join(models_used) }}</p>
        </div>

        <div class="section">
            <h2>ğŸ“Š æ•°æ®æ¦‚è§ˆ</h2>
            <p>æœ¬æ¬¡åˆ†æå…±åŒ…å« <strong>{{ data_info.n_samples }}</strong> ä¸ªæ ·æœ¬ï¼Œ<strong>{{ data_info.n_vars }}</strong> ä¸ªå˜é‡ã€‚</p>
        </div>

        <div class="section">
            <h2>ğŸ“ˆ æè¿°æ€§ç»Ÿè®¡</h2>
            <p>ä»¥ä¸‹æ˜¯å„å˜é‡çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ï¼š</p>
            <!-- æè¿°æ€§ç»Ÿè®¡è¡¨æ ¼å°†åœ¨è¿™é‡Œæ’å…¥ -->
        </div>

        {% if charts.distribution %}
        <div class="section">
            <h2>ğŸ“‰ æ•°æ®åˆ†å¸ƒå¯è§†åŒ–</h2>
            <div class="chart-container">
                <img src="{{ charts.distribution }}" alt="æ•°æ®åˆ†å¸ƒå›¾">
            </div>
        </div>
        {% endif %}

        {% if charts.correlation %}
        <div class="section">
            <h2>ğŸ”¥ ç›¸å…³æ€§åˆ†æ</h2>
            <div class="chart-container">
                <img src="{{ charts.correlation }}" alt="ç›¸å…³æ€§çƒ­åŠ›å›¾">
            </div>
        </div>
        {% endif %}

        {% if regression_results %}
        <div class="section">
            <h2>ğŸ“ å›å½’åˆ†æç»“æœ</h2>
            <p><strong>ç›®æ ‡å˜é‡:</strong> {{ regression_results.target }}</p>
            <p><strong>RÂ² å¾—åˆ†:</strong> {{ "%.3f"|format(regression_results.r2_score) }}</p>
            <h3>ç³»æ•°:</h3>
            <ul>
                {% for feature, coef in regression_results.coefficients.items() %}
                <li><code>{{ feature }}</code>: {{ "%.4f"|format(coef) }}</li>
                {% endfor %}
            </ul>
        </div>
        {% endif %}

        {% if old_plan_eval %}
        <div class="section">
            <h2>ğŸ” æ—§æ–¹æ¡ˆè¯„ä¼°</h2>
            <p>{{ old_plan_eval.summary }}</p>
            
            {% if old_plan_eval.strengths %}
            <h3>âœ… ä¼˜ç‚¹</h3>
            {% for strength in old_plan_eval.strengths %}
            <div class="strength">{{ strength }}</div>
            {% endfor %}
            {% endif %}

            {% if old_plan_eval.weaknesses %}
            <h3>âš ï¸ éœ€è¦æ”¹è¿›çš„åœ°æ–¹</h3>
            {% for weakness in old_plan_eval.weaknesses %}
            <div class="weakness">{{ weakness }}</div>
            {% endfor %}
            {% endif %}

            {% if old_plan_eval.recommendations %}
            <h3>ğŸ’¡ æ”¹è¿›å»ºè®®</h3>
            {% for rec in old_plan_eval.recommendations %}
            <div class="recommendation">{{ rec }}</div>
            {% endfor %}
            {% endif %}
        </div>
        {% endif %}

        <div class="section">
            <h2>ğŸ“ ç»“è®ºä¸å»ºè®®</h2>
            <p>åŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š</p>
            <ul>
                <li>æ•°æ®è´¨é‡è‰¯å¥½ï¼Œé€‚åˆè¿›è¡Œæ·±åº¦åˆ†æ</li>
                <li>å»ºè®®æ ¹æ®åˆ†æç»“æœåˆ¶å®šç›¸åº”çš„è¡ŒåŠ¨æ–¹æ¡ˆ</li>
                <li>å®šæœŸæ›´æ–°æ•°æ®ï¼ŒæŒç»­è·Ÿè¸ªåˆ†æ</li>
            </ul>
        </div>
    </div>
</body>
</html>
    """
    
    template = Template(html_template)
    html_content = template.render(
        title=title,
        generation_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        data_info=analysis_results.get('data_info', {}),
        models_used=analysis_results.get('models_used', []),
        charts=charts,
        regression_results=analysis_results.get('regression'),
        old_plan_eval=old_plan_eval
    )
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")


def main():
    parser = argparse.ArgumentParser(description='é—®å·è°ƒæŸ¥æŠ¥å‘Šæ•°æ®åˆ†æå·¥å…·')
    parser.add_argument('--data', required=True, help='é—®å·æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', default='output/report.html', help='è¾“å‡ºHTMLæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--old-plan', help='æ—§è°ƒç ”æ–¹æ¡ˆæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--model', default='auto', choices=['auto', 'descriptive', 'correlation', 'regression', 'cluster', 'factor'],
                       help='åˆ†ææ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤ï¼šautoè‡ªåŠ¨é€‰æ‹©ï¼‰')
    parser.add_argument('--title', default='é—®å·æ•°æ®åˆ†ææŠ¥å‘Š', help='æŠ¥å‘Šæ ‡é¢˜')
    parser.add_argument('--open-browser', action='store_true', default=True, help='æ˜¯å¦è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨')
    parser.add_argument('--verbose', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')
    
    args = parser.parse_args()
    
    try:
        # 1. åŠ è½½æ•°æ®
        print("ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶...")
        df = load_data_file(args.data)
        
        # 2. é€‰æ‹©åˆ†ææ¨¡å‹
        if args.model == 'auto':
            models = select_analysis_model(df)
        else:
            models = [args.model]
        
        # 3. æ‰§è¡Œåˆ†æ
        print("\nğŸ”¬ æ­£åœ¨æ‰§è¡Œæ•°æ®åˆ†æ...")
        analysis_results = {
            'data_info': {
                'n_samples': len(df),
                'n_vars': len(df.columns)
            },
            'models_used': models
        }
        
        if 'descriptive' in models:
            analysis_results['descriptive'] = perform_descriptive_analysis(df)
        
        if 'correlation' in models:
            analysis_results['correlation'] = perform_correlation_analysis(df)
        
        if 'regression' in models:
            analysis_results['regression'] = perform_regression_analysis(df)
        
        if 'cluster' in models:
            analysis_results['cluster'] = perform_cluster_analysis(df)
        
        if 'factor' in models:
            analysis_results['factor'] = perform_factor_analysis(df)
        
        # 4. ç”Ÿæˆå›¾è¡¨
        print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        output_dir = Path(args.output).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        charts = generate_charts(df, output_dir, args.output)
        
        # 5. è¯„ä¼°æ—§æ–¹æ¡ˆï¼ˆå¦‚æœæä¾›ï¼‰
        old_plan_eval = None
        if args.old_plan:
            print("\nğŸ” æ­£åœ¨è¯„ä¼°æ—§æ–¹æ¡ˆ...")
            old_plan_content = load_old_plan(args.old_plan)
            old_plan_eval = evaluate_old_plan(old_plan_content, analysis_results)
        
        # 6. ç”ŸæˆHTMLæŠ¥å‘Š
        print("\nğŸ“ æ­£åœ¨ç”ŸæˆHTMLæŠ¥å‘Š...")
        generate_html_report(analysis_results, charts, old_plan_eval, args.title, args.output)
        
        # 7. æ‰“å¼€æµè§ˆå™¨
        if args.open_browser:
            print(f"\nğŸŒ æ­£åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŠ¥å‘Š...")
            webbrowser.open(f'file://{os.path.abspath(args.output)}')
        
        print("\nâœ… åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}", file=sys.stderr)
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
