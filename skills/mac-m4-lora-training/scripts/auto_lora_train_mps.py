#!/usr/bin/env python3
"""
Mac M4 LoRAè‡ªåŠ¨åŒ–è®­ç»ƒè„šæœ¬
åªéœ€æä¾›åŸºæœ¬å‚æ•°å³å¯ä¸€é”®å¼€å§‹è®­ç»ƒ

ä½¿ç”¨æ–¹æ³•:
python auto_lora_train_mps.py --lora_name "my_character" --comfyui_dir "/path/to/ComfyUI" --train_dir "/path/to/images"
"""

import argparse
import subprocess
import shutil
import os
import sys
import json
import time
from pathlib import Path
import torch
from transformers import CLIPProcessor, CLIPModel

# ========================== æ ¸å¿ƒé…ç½® ==========================

# M4ä¸“å±åŸºç¡€å‚æ•°é…ç½®
BASE_PARAMS = {
    "network_dim": 32,
    "network_alpha": 32,
    "learning_rate": 2e-4,
    "train_batch_size": 2,  # M4æ¨èæ‰¹æ¬¡
    "max_train_epochs": 50,
    "clip_skip": 2,
    "lowram": True,
    "save_every_n_epochs": 10,
    "save_precision": "fp16",
    "resolution": "512,512",
    "device": "mps",
    "gradient_checkpointing": True,
    "mixed_precision": "fp16"
}

# åé¦ˆ-å‚æ•°æ˜ å°„è¡¨
FEEDBACK_PARAM_MAP = {
    "ç‰¹å¾ä¸æ˜æ˜¾": {
        "network_dim": lambda x: min(x+16, 64),
        "max_train_epochs": lambda x: x+20,
        "learning_rate": lambda x: x*1.1
    },
    "é£æ ¼åå·®å¤§": {
        "learning_rate": lambda x: x*0.5,
        "clip_skip": 1,
        "max_train_epochs": lambda x: max(x-10, 30)
    },
    "æ˜¾å­˜ä¸è¶³": {
        "train_batch_size": lambda x: max(1, x-1),
        "network_dim": lambda x: max(x-16, 16),
        "gradient_checkpointing": True
    },
    "è¿‡æ‹Ÿåˆ": {
        "learning_rate": lambda x: x*0.6,
        "max_train_epochs": lambda x: max(x-15, 20),
        "train_batch_size": lambda x: min(x+1, 3)
    }
}

# ========================== å·¥å…·å‡½æ•° ==========================

def print_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                Mac M4 LoRA è‡ªåŠ¨åŒ–è®­ç»ƒå·¥å…·                    â•‘
â•‘                                                              â•‘
â•‘  ğŸš€ ä¸“ä¸ºMac M4èŠ¯ç‰‡ä¼˜åŒ–                                        â•‘
â•‘  ğŸ§  æ™ºèƒ½å‚æ•°è°ƒä¼˜                                              â•‘
â•‘  ğŸ“Š å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹                                            â•‘
â•‘  ğŸ’¾ æ˜¾å­˜ä¼˜åŒ–ç®¡ç†                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def check_system_requirements():
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
    print("ğŸ” æ£€æŸ¥ç³»ç»Ÿè¦æ±‚...")
    
    # æ£€æŸ¥macOSç‰ˆæœ¬
    try:
        result = subprocess.run(['sw_vers', '-productVersion'], capture_output=True, text=True)
        macos_version = result.stdout.strip()
        print(f"   macOSç‰ˆæœ¬: {macos_version}")
        
        major_version = int(macos_version.split('.')[0])
        if major_version < 13:
            print("âŒ éœ€è¦macOS 13.0æˆ–æ›´é«˜ç‰ˆæœ¬ä»¥æ”¯æŒMPS")
            return False
    except:
        print("âš ï¸  æ— æ³•æ£€æµ‹macOSç‰ˆæœ¬")
    
    # æ£€æŸ¥MPSæ”¯æŒ
    try:
        import torch
        mps_available = torch.backends.mps.is_available()
        print(f"   MPSåŠ é€Ÿ: {'âœ… å¯ç”¨' if mps_available else 'âŒ ä¸å¯ç”¨'}")
        if not mps_available:
            print("âŒ MPSåŠ é€Ÿä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")
            return False
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False
    
    # æ£€æŸ¥å†…å­˜
    try:
        result = subprocess.run(['system_profiler', 'SPHardwareDataType'], capture_output=True, text=True)
        for line in result.stdout.split('\n'):
            if 'Memory:' in line:
                memory = line.split(':')[1].strip()
                print(f"   ç³»ç»Ÿå†…å­˜: {memory}")
                break
    except:
        print("âš ï¸  æ— æ³•æ£€æµ‹ç³»ç»Ÿå†…å­˜")
    
    print("âœ… ç³»ç»Ÿæ£€æŸ¥å®Œæˆ")
    return True

def setup_environment():
    """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
    print("ğŸ› ï¸  è®¾ç½®è®­ç»ƒç¯å¢ƒ...")
    
    # æ£€æŸ¥sd-scriptsç›®å½•
    if not os.path.exists('sd-scripts'):
        print("ğŸ“¥ å…‹éš†sd-scriptsä»“åº“...")
        try:
            subprocess.run(['git', 'clone', 'https://github.com/kohya-ss/sd-scripts.git'], check=True)
        except subprocess.CalledProcessError:
            print("âŒ å…‹éš†sd-scriptså¤±è´¥")
            return False
    
    # æ£€æŸ¥å¿…è¦çš„PythonåŒ…
    required_packages = ['torch', 'transformers', 'accelerate', 'pillow']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„PythonåŒ…: {', '.join(missing_packages)}")
        print("è¯·å…ˆå®‰è£…ä¾èµ–: pip install torch torchvision transformers accelerate pillow")
        return False
    
    print("âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ")
    return True

def get_user_inputs():
    """è·å–ç”¨æˆ·è¾“å…¥å‚æ•°"""
    parser = argparse.ArgumentParser(description="Mac M4 LoRA è‡ªåŠ¨è®­ç»ƒå·¥å…·")
    parser.add_argument("--lora_name", type=str, required=True, 
                       help="LoRAæ¨¡å‹åç§°ï¼ˆä¸å«åç¼€ï¼‰")
    parser.add_argument("--comfyui_dir", type=str, required=True, 
                       help="ComfyUIå®‰è£…ç›®å½•è·¯å¾„")
    parser.add_argument("--train_dir", type=str, required=True, 
                       help="è®­ç»ƒå›¾ç‰‡ç›®å½•è·¯å¾„")
    parser.add_argument("--trigger_word", type=str, default="", 
                       help="LoRAè§¦å‘è¯ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨lora_nameï¼‰")
    parser.add_argument("--feedback", type=str, default="", 
                       help="è®­ç»ƒåé¦ˆï¼ˆå¦‚'ç‰¹å¾ä¸æ˜æ˜¾'ï¼‰")
    parser.add_argument("--base_model", type=str, default="", 
                       help="åŸºç¡€æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    
    args = parser.parse_args()
    
    # è®¾ç½®é»˜è®¤è§¦å‘è¯
    if not args.trigger_word:
        args.trigger_word = args.lora_name
    
    return args

def validate_paths(args):
    """éªŒè¯è·¯å¾„æœ‰æ•ˆæ€§"""
    print("ğŸ“ éªŒè¯è·¯å¾„...")
    
    # æ£€æŸ¥è®­ç»ƒç›®å½•
    if not os.path.exists(args.train_dir):
        print(f"âŒ è®­ç»ƒç›®å½•ä¸å­˜åœ¨: {args.train_dir}")
        return False
    
    # æ£€æŸ¥è®­ç»ƒå›¾ç‰‡
    img_extensions = ('.png', '.jpg', '.jpeg', '.webp', '.bmp')
    image_files = [f for f in os.listdir(args.train_dir) 
                   if f.lower().endswith(img_extensions)]
    
    if len(image_files) == 0:
        print(f"âŒ è®­ç»ƒç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {args.train_dir}")
        return False
    
    print(f"   æ‰¾åˆ° {len(image_files)} å¼ è®­ç»ƒå›¾ç‰‡")
    
    # æ£€æŸ¥ComfyUIç›®å½•
    comfyui_lora_dir = os.path.join(args.comfyui_dir, "models", "loras")
    if not os.path.exists(comfyui_lora_dir):
        print(f"âŒ ComfyUI LoRAç›®å½•ä¸å­˜åœ¨: {comfyui_lora_dir}")
        print("è¯·ç¡®è®¤ComfyUIå®‰è£…è·¯å¾„æ­£ç¡®")
        return False
    
    print(f"   ComfyUI LoRAç›®å½•: {comfyui_lora_dir}")
    
    print("âœ… è·¯å¾„éªŒè¯å®Œæˆ")
    return True

def parse_feedback(feedback_text):
    """è§£æç”¨æˆ·åé¦ˆå¹¶è°ƒæ•´å‚æ•°"""
    adjusted_params = {}
    if not feedback_text:
        return adjusted_params
    
    print(f"ğŸ§  è§£æè®­ç»ƒåé¦ˆ: {feedback_text}")
    
    for keyword, param_rules in FEEDBACK_PARAM_MAP.items():
        if keyword in feedback_text:
            print(f"   æ£€æµ‹åˆ°å…³é”®è¯: {keyword}")
            for param, rule in param_rules.items():
                if callable(rule):
                    adjusted_params[param] = rule(BASE_PARAMS.get(param, 0))
                else:
                    adjusted_params[param] = rule
    
    if adjusted_params:
        print(f"   è°ƒæ•´å‚æ•°: {adjusted_params}")
    
    return adjusted_params

def generate_train_csv(train_dir, trigger_word):
    """ç”Ÿæˆè®­ç»ƒCSVæ–‡ä»¶"""
    print("ğŸ“ ç”Ÿæˆè®­ç»ƒæ ‡æ³¨æ–‡ä»¶...")
    
    csv_path = os.path.join(train_dir, "train.csv")
    img_extensions = ('.png', '.jpg', '.jpeg', '.webp', '.bmp')
    
    image_count = 0
    with open(csv_path, "w", encoding="utf-8") as f:
        for img_name in os.listdir(train_dir):
            if img_name.lower().endswith(img_extensions):
                img_path = os.path.join(train_dir, img_name)
                f.write(f"{img_path},{trigger_word}\n")
                image_count += 1
    
    print(f"   ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶: {csv_path}")
    print(f"   æ ‡æ³¨å›¾ç‰‡æ•°é‡: {image_count}")
    
    return csv_path

def create_config_file(train_dir):
    """åˆ›å»ºæ¨¡å‹é…ç½®æ–‡ä»¶"""
    config_dir = os.path.join("sd-scripts", "configs")
    os.makedirs(config_dir, exist_ok=True)
    
    config_path = os.path.join(config_dir, "training_config.yaml")
    
    config_content = """
model:
  model_type: "sd2"
  
training:
  resolution: 512
  clip_skip: 2
  gradient_checkpointing: true
  mixed_precision: "fp16"
  device: "mps"
"""
    
    with open(config_path, "w") as f:
        f.write(config_content)
    
    return config_path

def build_training_command(args, final_params, csv_path, config_path):
    """æ„å»ºè®­ç»ƒå‘½ä»¤"""
    print("ğŸ”§ æ„å»ºè®­ç»ƒå‘½ä»¤...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.join(args.train_dir, "lora_output")
    os.makedirs(output_dir, exist_ok=True)
    
    # åŸºç¡€å‘½ä»¤
    cmd = [
        "python", "train_network.py",
        "--train_data_dir", args.train_dir,
        "--output_dir", output_dir,
        "--network_module", "networks.lora",
        "--network_dim", str(final_params["network_dim"]),
        "--network_alpha", str(final_params["network_alpha"]),
        "--learning_rate", str(final_params["learning_rate"]),
        "--train_batch_size", str(final_params["train_batch_size"]),
        "--max_train_epochs", str(final_params["max_train_epochs"]),
        "--save_every_n_epochs", str(final_params["save_every_n_epochs"]),
        "--save_precision", final_params["save_precision"],
        "--resolution", final_params["resolution"],
        "--clip_skip", str(final_params["clip_skip"]),
        "--mixed_precision", final_params["mixed_precision"],
        "--output_name", args.lora_name
    ]
    
    # æ·»åŠ å¯é€‰å‚æ•°
    if final_params.get("lowram"):
        cmd.append("--lowram")
    
    if final_params.get("gradient_checkpointing"):
        cmd.append("--gradient_checkpointing")
    
    # å¦‚æœæœ‰åŸºç¡€æ¨¡å‹
    if args.base_model and os.path.exists(args.base_model):
        cmd.extend(["--pretrained_model_name_or_path", args.base_model])
    
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    
    return cmd, output_dir

def run_training(cmd):
    """æ‰§è¡Œè®­ç»ƒ"""
    print("ğŸš€ å¼€å§‹LoRAè®­ç»ƒ...")
    print(f"   è®­ç»ƒå‘½ä»¤: {' '.join(cmd)}")
    
    # åˆ‡æ¢åˆ°sd-scriptsç›®å½•
    original_dir = os.getcwd()
    os.chdir("sd-scripts")
    
    try:
        # æ‰§è¡Œè®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # å®æ—¶è¾“å‡ºè®­ç»ƒæ—¥å¿—
        for line in process.stdout:
            print(f"   {line.rstrip()}")
        
        process.wait()
        
        if process.returncode != 0:
            raise Exception(f"è®­ç»ƒå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
        
        print("âœ… è®­ç»ƒå®Œæˆ")
        
    finally:
        os.chdir(original_dir)

def copy_lora_to_comfyui(output_dir, lora_name, comfyui_dir):
    """æ‹·è´LoRAæ¨¡å‹åˆ°ComfyUI"""
    print("ğŸ“¦ éƒ¨ç½²LoRAæ¨¡å‹åˆ°ComfyUI...")
    
    # æŸ¥æ‰¾ç”Ÿæˆçš„LoRAæ–‡ä»¶
    lora_files = []
    for root, dirs, files in os.walk(output_dir):
        for file in files:
            if file.endswith(".safetensors") and lora_name in file:
                lora_files.append(os.path.join(root, file))
    
    if not lora_files:
        print("âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„LoRAæ¨¡å‹æ–‡ä»¶")
        return False
    
    # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
    latest_lora = max(lora_files, key=os.path.getmtime)
    print(f"   æ‰¾åˆ°LoRAæ–‡ä»¶: {os.path.basename(latest_lora)}")
    
    # æ‹·è´åˆ°ComfyUI
    comfyui_lora_dir = os.path.join(comfyui_dir, "models", "loras")
    target_path = os.path.join(comfyui_lora_dir, f"{lora_name}.safetensors")
    
    try:
        shutil.copy2(latest_lora, target_path)
        print(f"âœ… LoRAæ¨¡å‹å·²éƒ¨ç½²åˆ°: {target_path}")
        return True
    except Exception as e:
        print(f"âŒ æ‹·è´å¤±è´¥: {e}")
        return False

def save_training_log(args, final_params, success=True):
    """ä¿å­˜è®­ç»ƒæ—¥å¿—"""
    log_data = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "lora_name": args.lora_name,
        "train_dir": args.train_dir,
        "trigger_word": args.trigger_word,
        "feedback": args.feedback,
        "parameters": final_params,
        "success": success
    }
    
    log_file = os.path.join(args.train_dir, f"{args.lora_name}_training_log.json")
    with open(log_file, "w", encoding="utf-8") as f:
        json.dump(log_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {log_file}")

def print_summary(args, success=True):
    """æ‰“å°è®­ç»ƒæ€»ç»“"""
    print("\n" + "="*60)
    if success:
        print("ğŸ‰ LoRAè®­ç»ƒå®Œæˆï¼")
        print(f"   æ¨¡å‹åç§°: {args.lora_name}")
        print(f"   è§¦å‘è¯: {args.trigger_word}")
        print(f"   ComfyUIè·¯å¾„: {os.path.join(args.comfyui_dir, 'models', 'loras', f'{args.lora_name}.safetensors')}")
        print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print(f"   åœ¨ComfyUIä¸­åŠ è½½LoRA: {args.lora_name}.safetensors")
        print(f"   åœ¨æç¤ºè¯ä¸­ä½¿ç”¨: {args.trigger_word}")
    else:
        print("âŒ è®­ç»ƒå¤±è´¥")
        print("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•")
    print("="*60)

# ========================== ä¸»å‡½æ•° ==========================

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ‰“å°å¯åŠ¨æ¨ªå¹…
        print_banner()
        
        # è·å–ç”¨æˆ·è¾“å…¥
        args = get_user_inputs()
        
        # æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
        if not check_system_requirements():
            sys.exit(1)
        
        # è®¾ç½®ç¯å¢ƒ
        if not setup_environment():
            sys.exit(1)
        
        # éªŒè¯è·¯å¾„
        if not validate_paths(args):
            sys.exit(1)
        
        # è§£æåé¦ˆå¹¶è°ƒæ•´å‚æ•°
        adjusted_params = parse_feedback(args.feedback)
        final_params = {**BASE_PARAMS, **adjusted_params}
        
        print(f"ğŸ¯ æœ€ç»ˆè®­ç»ƒå‚æ•°:")
        for key, value in final_params.items():
            print(f"   {key}: {value}")
        
        # ç”Ÿæˆè®­ç»ƒæ–‡ä»¶
        csv_path = generate_train_csv(args.train_dir, args.trigger_word)
        config_path = create_config_file(args.train_dir)
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd, output_dir = build_training_command(args, final_params, csv_path, config_path)
        
        # æ‰§è¡Œè®­ç»ƒ
        run_training(cmd)
        
        # éƒ¨ç½²åˆ°ComfyUI
        copy_success = copy_lora_to_comfyui(output_dir, args.lora_name, args.comfyui_dir)
        
        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        save_training_log(args, final_params, copy_success)
        
        # æ‰“å°æ€»ç»“
        print_summary(args, copy_success)
        
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()